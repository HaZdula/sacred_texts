{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from textblob import Word\n",
    "\n",
    "from get_nice_text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_nice_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install spacy\n",
    "python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buddha PERSON\n",
      "Rahula PERSON\n",
      "The Buddha Rahula GPE\n",
      "Rahula The Buddha PERSON\n",
      "Rahula GPE\n",
      "The Buddha WORK_OF_ART\n",
      "Rahula PERSON\n",
      "Rahula PERSON\n",
      "Gratified PERSON\n",
      "Rahula PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "  \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "  \n",
    "sentence = str(data[0])\n",
    "  \n",
    "doc = nlp(sentence) \n",
    "  \n",
    "for ent in doc.ents: \n",
    "    print(ent.text, ent.label_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want only persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(data):\n",
    "\n",
    "    def unique(arr): \n",
    "    \n",
    "        un = []\n",
    "\n",
    "        for elem in arr: \n",
    "            if  elem not in un : \n",
    "                un.append(elem)\n",
    "\n",
    "        return un\n",
    "\n",
    "    entities_list = []\n",
    "    for i in range(len(data)):\n",
    "        chapter = str(data[i])\n",
    "        doc = nlp(chapter) \n",
    "\n",
    "        for ent in doc.ents: \n",
    "            extracted_ent = [ent.text, ent.label_]\n",
    "            entities_list.append(extracted_ent)\n",
    "    \n",
    "    out = unique(entities_list)\n",
    "    \n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = get_entities(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Buddha', 'PERSON'],\n",
       " ['Rahula', 'PERSON'],\n",
       " ['The Buddha Rahula', 'GPE'],\n",
       " ['Rahula The Buddha', 'PERSON'],\n",
       " ['Rahula', 'GPE'],\n",
       " ['The Buddha', 'WORK_OF_ART'],\n",
       " ['Gratified', 'PERSON'],\n",
       " ['Kosambi', 'GPE'],\n",
       " ['Simsapa', 'PERSON'],\n",
       " ['Birth', 'PERSON'],\n",
       " ['five', 'CARDINAL'],\n",
       " ['one', 'CARDINAL'],\n",
       " ['two', 'CARDINAL'],\n",
       " ['three', 'CARDINAL'],\n",
       " ['twelve', 'CARDINAL'],\n",
       " ['four', 'CARDINAL'],\n",
       " ['Unprovoked', 'GPE'],\n",
       " ['Savatthi', 'ORG'],\n",
       " ['Monks', 'NORP'],\n",
       " ['The Buddha  Clinging', 'WORK_OF_ART'],\n",
       " ['MahaKotthita', 'ORG'],\n",
       " ['MahaKotthita Sariputta', 'PRODUCT'],\n",
       " ['earth', 'LOC'],\n",
       " ['Sariputta', 'PRODUCT'],\n",
       " ['the internal water property', 'ORG'],\n",
       " ['phlegm', 'PERSON'],\n",
       " ['the external water property', 'ORG'],\n",
       " ['windy', 'PERSON'],\n",
       " ['Sister Dhammadinna', 'PERSON'],\n",
       " ['six', 'CARDINAL'],\n",
       " ['Consciousness   Consciousness', 'ORG'],\n",
       " ['Dhamma', 'ORG'],\n",
       " ['First', 'ORDINAL'],\n",
       " ['Release', 'PRODUCT'],\n",
       " ['Dispassion', 'ORG'],\n",
       " ['Consciousness    Fabrications    ', 'ORG'],\n",
       " ['One', 'CARDINAL'],\n",
       " ['Consciousness', 'ORG'],\n",
       " ['Birth', 'PRODUCT'],\n",
       " ['second', 'ORDINAL']]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it makes sance, sometimes it doesn't but it is more or less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization - converting to root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ing   We have thought of ourselves  perhaps  as creatures moving upon this earth  rather helpless  at the mercy of storm and hunger and our enemies  We are to think of ourselves as immortals  dwelling in the Light  encompassed and sustained by spiritual powers  The steady effort to hold this thought will awaken dormant and unrealized powers  which will unveil to us the nearness of the Eternal   '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data[300])[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ing We have thought of ourselves perhaps a creature moving upon this earth rather helpless at the mercy of storm and hunger and our enemy We are to think of ourselves a immortal dwelling in the Light encompassed and sustained by spiritual power The steady effort to hold this thought will awaken dormant and unrealized power which will unveil to u the nearness of the Eternal'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = \" \".join([Word(word).lemmatize() for word in str(data[300]).split()])\n",
    "tmp[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming - getting \"base\" of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' set before thy face      And put a knife to thy throat  if it be so that thou have thy soul in thy own power      Be not desirous of his meats  in which is the bread of deceit      Labour not to be rich  but set bounds to thy prudence      Lift not up thy eyes to riches which thou canst not have  because they shall make themselves wings like those of an eagle  and shall fly towards heaven      Eat not with an envious man  and desire not his meats      Because  like a soothsayer  and diviner  he'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data[500])[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set befor thi face and put a knife to thi throat if it be so that thou have thi soul in thi own power Be not desir of hi meat in which is the bread of deceit labour not to be rich but set bound to thi prudenc lift not up thi eye to rich which thou canst not have becaus they shall make themselv wing like those of an eagl and shall fli toward heaven eat not with an enviou man and desir not hi meat becaus like a soothsay and divin he thinketh that which he knoweth not eat and drink will he say to '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = \" \".join([Word(word).stem() for word in str(data[500]).split()])\n",
    "tmp[:499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set', 'befor', 'thi', 'face', 'and', 'put', 'a', 'knife', 'to', 'thi']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [Word(word).stem() for word in str(data[500]).split()]\n",
    "tmp[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not getting the ending?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['set', 'before', 'thy', 'face', 'And', 'put', 'a', 'knife', 'to', 'thy'],\n",
       " ['set', 'befor', 'thi', 'face', 'and', 'put', 'a', 'knife', 'to', 'thi'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = str(data[500]).split()\n",
    "stemmed = tmp\n",
    "base[:10], stemmed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ending(base, stemmed): \n",
    "    \"\"\"\n",
    "    returns list of endings, so it might be different length from original vectors (when there is no ending)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for i in range(len(base)): \n",
    "        st = stemmed[i]\n",
    "        bs = base[i]\n",
    "        diff = len(bs) - len(st)\n",
    "        \n",
    "        if diff > 0 : \n",
    "            out.append(base[i][-diff:])\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'ous', 's', 's', 's', 'e', 's', 'es', 'e', 'es']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ending(base, stemmed)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets just the ending and if there is no ending than gives space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_endings(data):\n",
    "    n = len(data)\n",
    "    \n",
    "    dicts = [0 for i in range(n)]\n",
    "    for i in range(n):\n",
    "        chapter = data[i]\n",
    "        stemmed = [Word(word).stem() for word in str(chapter).split()]\n",
    "        base = str(chapter).split()\n",
    "        \n",
    "        endings = get_ending(base, stemmed)\n",
    "        \n",
    "        # makes dictionary\n",
    "        counted = Counter(endings)\n",
    "        dicts[i] = counted\n",
    "        \n",
    "    return(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'ion': 30,\n",
       "          's': 51,\n",
       "          'ed': 19,\n",
       "          'er': 1,\n",
       "          'lful': 5,\n",
       "          'ful': 17,\n",
       "          'ences': 8,\n",
       "          'ely': 1,\n",
       "          'e': 9,\n",
       "          'ing': 7,\n",
       "          'ng': 3,\n",
       "          'eable': 1,\n",
       "          'ly': 2,\n",
       "          'es': 2,\n",
       "          'ated': 1,\n",
       "          'atives': 3}),\n",
       " Counter({'e': 11,\n",
       "          'ed': 5,\n",
       "          's': 20,\n",
       "          'ing': 8,\n",
       "          'es': 3,\n",
       "          'ous': 3,\n",
       "          'ment': 2,\n",
       "          'ion': 8,\n",
       "          'ation': 3}),\n",
       " Counter({'e': 16,\n",
       "          's': 36,\n",
       "          'ity': 4,\n",
       "          'ion': 11,\n",
       "          'ful': 8,\n",
       "          'ng': 5,\n",
       "          'ation': 4,\n",
       "          'd': 2,\n",
       "          'ting': 1,\n",
       "          'ed': 5,\n",
       "          'ing': 3,\n",
       "          'ates': 1,\n",
       "          'es': 2,\n",
       "          'ered': 1,\n",
       "          'ment': 1,\n",
       "          'fulness': 1,\n",
       "          'ative': 1,\n",
       "          'ions': 1}),\n",
       " Counter({'e': 31,\n",
       "          'ing': 9,\n",
       "          'ment': 1,\n",
       "          'ation': 4,\n",
       "          's': 30,\n",
       "          'ed': 11,\n",
       "          'ion': 6,\n",
       "          'ations': 2,\n",
       "          'ly': 2,\n",
       "          'led': 2}),\n",
       " Counter({'s': 2, 'fulness': 5, 'ation': 1, 'e': 1})]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_endings = count_endings(data)\n",
    "list_of_endings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
